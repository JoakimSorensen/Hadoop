2017-09-22 08:59:06,824 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = Joakims-MacBook-Pro.local/218.38.137.27
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.1
STARTUP_MSG:   classpath = /usr/local/Cellar/hadoop/2.6.1/etc/hadoop:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/activation-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/hadoop-annotations-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/hadoop-auth-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/xz-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/hadoop-common-2.6.1-tests.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/hadoop-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/hadoop-nfs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/hadoop-hdfs-2.6.1-tests.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/hadoop-hdfs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-api-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-client-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-registry-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.1-tests.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b4d876d837b830405ccdb6af94742f99d49f9c04; compiled by 'jenkins' on 2015-09-16T21:07Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2017-09-22 08:59:06,835 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-22 08:59:06,838 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-22 08:59:07,177 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-22 08:59:07,321 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-09-22 08:59:07,321 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-22 08:59:07,322 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-22 08:59:07,323 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-22 08:59:07,401 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-22 08:59:07,540 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-22 08:59:07,583 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-22 08:59:07,589 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-22 08:59:07,604 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-22 08:59:07,606 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-22 08:59:07,606 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-22 08:59:07,607 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-22 08:59:07,636 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-22 08:59:07,638 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-22 08:59:07,671 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-22 08:59:07,671 INFO org.mortbay.log: jetty-6.1.26
2017-09-22 08:59:07,909 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-22 08:59:07,939 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-22 08:59:07,939 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-22 08:59:07,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2017-09-22 08:59:07,975 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2017-09-22 08:59:08,015 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-22 08:59:08,015 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-22 08:59:08,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-22 08:59:08,021 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 sep 22 08:59:08
2017-09-22 08:59:08,023 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-22 08:59:08,023 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 08:59:08,026 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-22 08:59:08,026 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-22 08:59:08,034 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-22 08:59:08,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-22 08:59:08,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-22 08:59:08,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-22 08:59:08,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-22 08:59:08,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2017-09-22 08:59:08,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-22 08:59:08,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-22 08:59:08,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-22 08:59:08,043 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = Jocke (auth:SIMPLE)
2017-09-22 08:59:08,043 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-22 08:59:08,043 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-22 08:59:08,044 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-22 08:59:08,045 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-22 08:59:08,243 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-22 08:59:08,243 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 08:59:08,243 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-22 08:59:08,243 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-22 08:59:08,244 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2017-09-22 08:59:08,250 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-22 08:59:08,250 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 08:59:08,250 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-22 08:59:08,250 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-22 08:59:08,252 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-22 08:59:08,252 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-22 08:59:08,253 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-22 08:59:08,254 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-22 08:59:08,254 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-22 08:59:08,256 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-22 08:59:08,256 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 08:59:08,256 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-22 08:59:08,256 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-22 08:59:08,260 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2017-09-22 08:59:08,260 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2017-09-22 08:59:08,260 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2017-09-22 08:59:08,277 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-Jocke/dfs/name/in_use.lock acquired by nodename 57537@Joakims-MacBook-Pro.local
2017-09-22 08:59:08,342 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-Jocke/dfs/name/current
2017-09-22 08:59:08,343 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2017-09-22 08:59:08,387 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2017-09-22 08:59:08,414 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-22 08:59:08,414 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-Jocke/dfs/name/current/fsimage_0000000000000000000
2017-09-22 08:59:08,419 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-09-22 08:59:08,419 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2017-09-22 08:59:08,571 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-22 08:59:08,572 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 312 msecs
2017-09-22 08:59:08,796 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-22 08:59:08,802 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-09-22 08:59:08,813 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-22 08:59:08,847 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-22 08:59:08,860 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-22 08:59:08,860 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-22 08:59:08,860 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2017-09-22 08:59:08,861 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2017-09-22 08:59:08,861 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2017-09-22 08:59:08,861 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-09-22 08:59:08,875 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2017-09-22 08:59:08,875 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-09-22 08:59:08,875 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2017-09-22 08:59:08,875 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-09-22 08:59:08,875 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2017-09-22 08:59:08,875 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2017-09-22 08:59:08,887 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-22 08:59:08,887 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-22 08:59:08,889 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-22 08:59:08,889 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-22 08:59:08,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-22 08:59:08,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 285243849 milliseconds
2017-09-22 08:59:08,896 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-09-22 08:59:13,029 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, datanodeUuid=3a973e04-e1c2-4a68-ab9b-943f6c0f7037, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-dbe0b9c4-bc04-430e-9745-5ee3219683b3;nsid=1125058093;c=0) storage 3a973e04-e1c2-4a68-ab9b-943f6c0f7037
2017-09-22 08:59:13,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2017-09-22 08:59:13,037 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-22 08:59:13,111 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2017-09-22 08:59:13,111 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-0ce65e9d-615d-4060-9c9e-d0b3ceb30109 for DN 127.0.0.1:50010
2017-09-22 08:59:13,153 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-0ce65e9d-615d-4060-9c9e-d0b3ceb30109,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-09-22 08:59:13,153 INFO BlockStateChange: BLOCK* processReport: from storage DS-0ce65e9d-615d-4060-9c9e-d0b3ceb30109 node DatanodeRegistration(127.0.0.1, datanodeUuid=3a973e04-e1c2-4a68-ab9b-943f6c0f7037, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-dbe0b9c4-bc04-430e-9745-5ee3219683b3;nsid=1125058093;c=0), blocks: 0, hasStaleStorages: false, processing time: 1 msecs
2017-09-22 08:59:32,140 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-22 08:59:32,142 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at Joakims-MacBook-Pro.local/218.38.137.27
************************************************************/
2017-09-22 09:00:15,333 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = Joakims-MacBook-Pro.local/218.38.137.27
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.1
STARTUP_MSG:   classpath = /usr/local/Cellar/hadoop/2.6.1/etc/hadoop:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/activation-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/hadoop-annotations-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/hadoop-auth-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/xz-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/hadoop-common-2.6.1-tests.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/hadoop-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/hadoop-nfs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/hadoop-hdfs-2.6.1-tests.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/hadoop-hdfs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-api-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-client-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-registry-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.1-tests.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b4d876d837b830405ccdb6af94742f99d49f9c04; compiled by 'jenkins' on 2015-09-16T21:07Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2017-09-22 09:00:15,344 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-22 09:00:15,346 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-22 09:00:15,680 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-22 09:00:15,787 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-09-22 09:00:15,787 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-22 09:00:15,789 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-22 09:00:15,790 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-22 09:00:15,869 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-22 09:00:16,000 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-22 09:00:16,042 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-22 09:00:16,048 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-22 09:00:16,061 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-22 09:00:16,064 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-22 09:00:16,064 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-22 09:00:16,064 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-22 09:00:16,100 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-22 09:00:16,102 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-22 09:00:16,127 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-22 09:00:16,128 INFO org.mortbay.log: jetty-6.1.26
2017-09-22 09:00:16,343 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-22 09:00:16,373 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-22 09:00:16,373 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-22 09:00:16,406 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2017-09-22 09:00:16,412 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2017-09-22 09:00:16,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-22 09:00:16,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-22 09:00:16,457 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-22 09:00:16,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 sep 22 09:00:16
2017-09-22 09:00:16,462 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-22 09:00:16,462 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 09:00:16,463 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-22 09:00:16,463 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-22 09:00:16,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-22 09:00:16,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-22 09:00:16,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-22 09:00:16,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-22 09:00:16,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-22 09:00:16,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2017-09-22 09:00:16,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-22 09:00:16,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-22 09:00:16,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-22 09:00:16,483 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = Jocke (auth:SIMPLE)
2017-09-22 09:00:16,483 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-22 09:00:16,483 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-22 09:00:16,484 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-22 09:00:16,485 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-22 09:00:16,695 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-22 09:00:16,695 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 09:00:16,695 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-22 09:00:16,695 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-22 09:00:16,696 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2017-09-22 09:00:16,703 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-22 09:00:16,703 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 09:00:16,703 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-22 09:00:16,703 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-22 09:00:16,704 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-22 09:00:16,704 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-22 09:00:16,704 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-22 09:00:16,705 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-22 09:00:16,705 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-22 09:00:16,707 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-22 09:00:16,707 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 09:00:16,707 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-22 09:00:16,707 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-22 09:00:16,710 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2017-09-22 09:00:16,711 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2017-09-22 09:00:16,711 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2017-09-22 09:00:16,726 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-Jocke/dfs/name/in_use.lock acquired by nodename 58474@Joakims-MacBook-Pro.local
2017-09-22 09:00:16,791 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-Jocke/dfs/name/current
2017-09-22 09:00:16,840 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-Jocke/dfs/name/current/edits_inprogress_0000000000000000001 -> /tmp/hadoop-Jocke/dfs/name/current/edits_0000000000000000001-0000000000000000001
2017-09-22 09:00:16,879 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2017-09-22 09:00:16,906 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-22 09:00:16,907 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-Jocke/dfs/name/current/fsimage_0000000000000000000
2017-09-22 09:00:16,907 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6b7906b3 expecting start txid #1
2017-09-22 09:00:16,907 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-Jocke/dfs/name/current/edits_0000000000000000001-0000000000000000001
2017-09-22 09:00:16,909 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/tmp/hadoop-Jocke/dfs/name/current/edits_0000000000000000001-0000000000000000001' to transaction ID 1
2017-09-22 09:00:16,913 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-Jocke/dfs/name/current/edits_0000000000000000001-0000000000000000001 of size 1048576 edits # 1 loaded in 0 seconds
2017-09-22 09:00:16,915 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-09-22 09:00:16,915 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 2
2017-09-22 09:00:17,057 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-22 09:00:17,057 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 346 msecs
2017-09-22 09:00:17,279 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-22 09:00:17,285 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-09-22 09:00:17,296 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-22 09:00:17,321 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-22 09:00:17,335 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-22 09:00:17,336 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-22 09:00:17,336 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2017-09-22 09:00:17,336 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2017-09-22 09:00:17,336 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2017-09-22 09:00:17,336 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-09-22 09:00:17,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2017-09-22 09:00:17,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-09-22 09:00:17,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2017-09-22 09:00:17,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-09-22 09:00:17,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2017-09-22 09:00:17,349 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec
2017-09-22 09:00:17,363 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-22 09:00:17,363 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-22 09:00:17,365 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-22 09:00:17,365 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-22 09:00:17,370 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-22 09:00:17,370 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 285312327 milliseconds
2017-09-22 09:00:17,372 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 3 millisecond(s).
2017-09-22 09:00:21,511 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, datanodeUuid=3a973e04-e1c2-4a68-ab9b-943f6c0f7037, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-dbe0b9c4-bc04-430e-9745-5ee3219683b3;nsid=1125058093;c=0) storage 3a973e04-e1c2-4a68-ab9b-943f6c0f7037
2017-09-22 09:00:21,518 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2017-09-22 09:00:21,519 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-22 09:00:21,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2017-09-22 09:00:21,596 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-0ce65e9d-615d-4060-9c9e-d0b3ceb30109 for DN 127.0.0.1:50010
2017-09-22 09:00:21,636 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-0ce65e9d-615d-4060-9c9e-d0b3ceb30109,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-09-22 09:00:21,637 INFO BlockStateChange: BLOCK* processReport: from storage DS-0ce65e9d-615d-4060-9c9e-d0b3ceb30109 node DatanodeRegistration(127.0.0.1, datanodeUuid=3a973e04-e1c2-4a68-ab9b-943f6c0f7037, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-dbe0b9c4-bc04-430e-9745-5ee3219683b3;nsid=1125058093;c=0), blocks: 0, hasStaleStorages: false, processing time: 2 msecs
2017-09-22 09:00:47,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-09-22 09:00:47,370 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 09:01:17,370 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-09-22 09:01:17,371 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 09:01:26,734 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-22 09:01:26,735 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-22 09:01:26,735 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 2
2017-09-22 09:01:26,735 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 5 
2017-09-22 09:01:26,736 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 6 
2017-09-22 09:01:26,738 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-Jocke/dfs/name/current/edits_inprogress_0000000000000000002 -> /tmp/hadoop-Jocke/dfs/name/current/edits_0000000000000000002-0000000000000000003
2017-09-22 09:01:26,738 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4
2017-09-22 09:01:27,613 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0,00s at 0,00 KB/s
2017-09-22 09:01:27,614 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000003 size 352 bytes.
2017-09-22 09:01:27,617 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2017-09-22 09:01:47,371 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-09-22 09:01:47,372 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 09:02:17,372 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-09-22 09:02:17,373 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 09:02:47,373 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-09-22 09:02:47,373 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 09:03:17,377 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 09:03:17,377 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 09:03:47,379 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-09-22 09:03:47,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 09:04:17,382 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30004 milliseconds
2017-09-22 09:04:17,383 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 09:04:47,382 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-09-22 09:04:47,383 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 09:05:17,385 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-09-22 09:05:17,385 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 09:05:47,389 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 09:05:47,390 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 09:06:06,496 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-22 09:06:06,498 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at Joakims-MacBook-Pro.local/218.38.137.27
************************************************************/
2017-09-22 10:02:32,030 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = Joakims-MacBook-Pro.local/218.38.137.27
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.1
STARTUP_MSG:   classpath = /usr/local/Cellar/hadoop/2.6.1/etc/hadoop:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/activation-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/hadoop-annotations-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/hadoop-auth-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/xz-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/hadoop-common-2.6.1-tests.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/hadoop-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/hadoop-nfs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/hadoop-hdfs-2.6.1-tests.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/hadoop-hdfs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-api-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-client-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-registry-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.1-tests.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b4d876d837b830405ccdb6af94742f99d49f9c04; compiled by 'jenkins' on 2015-09-16T21:07Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2017-09-22 10:02:32,041 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-22 10:02:32,049 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-22 10:02:32,410 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-22 10:02:32,529 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-09-22 10:02:32,529 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-22 10:02:32,530 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-22 10:02:32,531 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-22 10:02:32,624 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-22 10:02:32,776 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-22 10:02:32,840 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-22 10:02:32,847 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-22 10:02:32,863 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-22 10:02:32,866 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-22 10:02:32,866 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-22 10:02:32,866 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-22 10:02:32,909 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-22 10:02:32,911 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-22 10:02:32,942 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-22 10:02:32,942 INFO org.mortbay.log: jetty-6.1.26
2017-09-22 10:02:33,195 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-22 10:02:33,241 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-22 10:02:33,241 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-22 10:02:33,290 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2017-09-22 10:02:33,298 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2017-09-22 10:02:33,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-22 10:02:33,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-22 10:02:33,358 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-22 10:02:33,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 sep 22 10:02:33
2017-09-22 10:02:33,362 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-22 10:02:33,362 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 10:02:33,364 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-22 10:02:33,364 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-22 10:02:33,375 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-22 10:02:33,375 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-22 10:02:33,375 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-22 10:02:33,375 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-22 10:02:33,375 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-22 10:02:33,375 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2017-09-22 10:02:33,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-22 10:02:33,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-22 10:02:33,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-22 10:02:33,385 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = Jocke (auth:SIMPLE)
2017-09-22 10:02:33,385 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-22 10:02:33,385 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-22 10:02:33,385 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-22 10:02:33,387 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-22 10:02:33,608 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-22 10:02:33,608 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 10:02:33,608 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-22 10:02:33,608 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-22 10:02:33,609 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2017-09-22 10:02:33,618 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-22 10:02:33,618 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 10:02:33,619 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-22 10:02:33,619 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-22 10:02:33,621 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-22 10:02:33,621 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-22 10:02:33,621 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-22 10:02:33,622 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-22 10:02:33,622 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-22 10:02:33,625 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-22 10:02:33,625 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 10:02:33,626 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-22 10:02:33,626 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-22 10:02:33,630 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2017-09-22 10:02:33,630 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2017-09-22 10:02:33,630 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2017-09-22 10:02:33,632 WARN org.apache.hadoop.hdfs.server.common.Storage: Storage directory /usr/local/Cellar/hadoop/hdfs/tmp2/dfs/name does not exist
2017-09-22 10:02:33,633 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Encountered exception loading fsimage
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /usr/local/Cellar/hadoop/hdfs/tmp2/dfs/name is in an inconsistent state: storage directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:314)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:202)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1022)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:741)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:538)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:597)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:764)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:748)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1507)
2017-09-22 10:02:33,640 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-22 10:02:33,745 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NameNode metrics system...
2017-09-22 10:02:33,746 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system stopped.
2017-09-22 10:02:33,746 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system shutdown complete.
2017-09-22 10:02:33,746 FATAL org.apache.hadoop.hdfs.server.namenode.NameNode: Failed to start namenode.
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /usr/local/Cellar/hadoop/hdfs/tmp2/dfs/name is in an inconsistent state: storage directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:314)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:202)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1022)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:741)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:538)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:597)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:764)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:748)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1507)
2017-09-22 10:02:33,748 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2017-09-22 10:02:33,750 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at Joakims-MacBook-Pro.local/218.38.137.27
************************************************************/
2017-09-22 10:33:12,584 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = Joakims-MacBook-Pro.local/218.38.137.27
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.1
STARTUP_MSG:   classpath = /usr/local/Cellar/hadoop/2.6.1/etc/hadoop:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/activation-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/hadoop-annotations-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/hadoop-auth-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/xz-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/hadoop-common-2.6.1-tests.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/hadoop-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/hadoop-nfs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/hadoop-hdfs-2.6.1-tests.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/hadoop-hdfs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-api-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-client-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-registry-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.1-tests.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b4d876d837b830405ccdb6af94742f99d49f9c04; compiled by 'jenkins' on 2015-09-16T21:07Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2017-09-22 10:33:12,596 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-22 10:33:12,601 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-22 10:33:12,948 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-22 10:33:13,104 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-09-22 10:33:13,104 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-22 10:33:13,105 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-22 10:33:13,106 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-22 10:33:13,197 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-22 10:33:13,344 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-22 10:33:13,410 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-22 10:33:13,416 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-22 10:33:13,432 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-22 10:33:13,435 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-22 10:33:13,435 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-22 10:33:13,435 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-22 10:33:13,478 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-22 10:33:13,481 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-22 10:33:13,516 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-22 10:33:13,516 INFO org.mortbay.log: jetty-6.1.26
2017-09-22 10:33:13,778 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-22 10:33:13,821 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-22 10:33:13,821 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-22 10:33:13,868 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2017-09-22 10:33:13,878 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2017-09-22 10:33:13,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-22 10:33:13,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-22 10:33:13,936 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-22 10:33:13,938 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 sep 22 10:33:13
2017-09-22 10:33:13,940 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-22 10:33:13,940 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 10:33:13,944 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-22 10:33:13,944 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-22 10:33:13,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-22 10:33:13,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-22 10:33:13,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-22 10:33:13,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-22 10:33:13,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-22 10:33:13,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2017-09-22 10:33:13,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-22 10:33:13,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-22 10:33:13,954 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-22 10:33:13,963 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = Jocke (auth:SIMPLE)
2017-09-22 10:33:13,963 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-22 10:33:13,963 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-22 10:33:13,963 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-22 10:33:13,965 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-22 10:33:14,230 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-22 10:33:14,230 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 10:33:14,230 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-22 10:33:14,230 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-22 10:33:14,231 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2017-09-22 10:33:14,240 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-22 10:33:14,240 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 10:33:14,240 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-22 10:33:14,240 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-22 10:33:14,242 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-22 10:33:14,243 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-22 10:33:14,243 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-22 10:33:14,244 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-22 10:33:14,244 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-22 10:33:14,247 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-22 10:33:14,247 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 10:33:14,247 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-22 10:33:14,247 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-22 10:33:14,251 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2017-09-22 10:33:14,252 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2017-09-22 10:33:14,252 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2017-09-22 10:33:14,273 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/Cellar/hadoop/hdfs/tmp2/dfs/name/in_use.lock acquired by nodename 60755@Joakims-MacBook-Pro.local
2017-09-22 10:33:14,338 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /usr/local/Cellar/hadoop/hdfs/tmp2/dfs/name/current
2017-09-22 10:33:14,338 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2017-09-22 10:33:14,395 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2017-09-22 10:33:14,426 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-22 10:33:14,427 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /usr/local/Cellar/hadoop/hdfs/tmp2/dfs/name/current/fsimage_0000000000000000000
2017-09-22 10:33:14,433 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-09-22 10:33:14,433 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2017-09-22 10:33:14,598 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-22 10:33:14,598 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 346 msecs
2017-09-22 10:33:14,921 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-22 10:33:14,929 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-09-22 10:33:14,944 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-22 10:33:14,974 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-22 10:33:14,988 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-22 10:33:14,988 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-22 10:33:14,988 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2017-09-22 10:33:14,988 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2017-09-22 10:33:14,988 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2017-09-22 10:33:14,988 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-09-22 10:33:15,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2017-09-22 10:33:15,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-09-22 10:33:15,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2017-09-22 10:33:15,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-09-22 10:33:15,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2017-09-22 10:33:15,005 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 17 msec
2017-09-22 10:33:15,024 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-22 10:33:15,024 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-22 10:33:15,027 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-22 10:33:15,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-22 10:33:15,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-22 10:33:15,032 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 290890136 milliseconds
2017-09-22 10:33:15,034 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-09-22 10:33:18,848 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, datanodeUuid=87b73037-5265-4062-ab2a-5fc99bc12733, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-1a207d0b-a6a6-4025-85b9-f75ccda1fcb0;nsid=1188721184;c=0) storage 87b73037-5265-4062-ab2a-5fc99bc12733
2017-09-22 10:33:18,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2017-09-22 10:33:18,858 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-22 10:33:18,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2017-09-22 10:33:18,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-71188f24-74f5-441b-ba70-8601b599671b for DN 127.0.0.1:50010
2017-09-22 10:33:18,989 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-71188f24-74f5-441b-ba70-8601b599671b,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-09-22 10:33:18,989 INFO BlockStateChange: BLOCK* processReport: from storage DS-71188f24-74f5-441b-ba70-8601b599671b node DatanodeRegistration(127.0.0.1, datanodeUuid=87b73037-5265-4062-ab2a-5fc99bc12733, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-1a207d0b-a6a6-4025-85b9-f75ccda1fcb0;nsid=1188721184;c=0), blocks: 0, hasStaleStorages: false, processing time: 2 msecs
2017-09-22 10:33:45,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-09-22 10:33:45,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:34:15,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-09-22 10:34:15,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:34:23,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-22 10:34:23,755 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-22 10:34:23,756 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1
2017-09-22 10:34:23,756 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 5 
2017-09-22 10:34:23,756 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 5 
2017-09-22 10:34:23,758 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /usr/local/Cellar/hadoop/hdfs/tmp2/dfs/name/current/edits_inprogress_0000000000000000001 -> /usr/local/Cellar/hadoop/hdfs/tmp2/dfs/name/current/edits_0000000000000000001-0000000000000000002
2017-09-22 10:34:23,760 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3
2017-09-22 10:34:24,660 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0,00s at 0,00 KB/s
2017-09-22 10:34:24,660 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000002 size 352 bytes.
2017-09-22 10:34:24,663 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2017-09-22 10:34:45,039 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30004 milliseconds
2017-09-22 10:34:45,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:35:15,044 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:35:15,044 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:35:45,048 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30006 milliseconds
2017-09-22 10:35:45,049 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:36:15,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30004 milliseconds
2017-09-22 10:36:15,053 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:36:45,051 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-09-22 10:36:45,051 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:37:15,056 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:37:15,056 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:37:45,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:37:45,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:38:15,059 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-09-22 10:38:15,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:38:45,064 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:38:45,065 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:39:15,068 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:39:15,068 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:39:45,069 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-09-22 10:39:45,070 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:40:15,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:40:15,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:40:45,078 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:40:45,078 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:41:15,080 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-09-22 10:41:15,081 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:41:45,080 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-09-22 10:41:45,080 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:42:15,083 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30004 milliseconds
2017-09-22 10:42:15,084 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:42:45,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-09-22 10:42:45,086 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:43:15,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:43:15,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:43:45,093 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:43:45,094 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:43:46,050 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-09-22 10:43:46,052 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at Joakims-MacBook-Pro.local/218.38.137.27
************************************************************/
2017-09-22 10:44:34,363 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = Joakims-MacBook-Pro.local/218.38.137.27
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.1
STARTUP_MSG:   classpath = /usr/local/Cellar/hadoop/2.6.1/etc/hadoop:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/activation-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/hadoop-annotations-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/hadoop-auth-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/xz-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/hadoop-common-2.6.1-tests.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/hadoop-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/common/hadoop-nfs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/hadoop-hdfs-2.6.1-tests.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/hadoop-hdfs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-api-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-client-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-registry-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.1-tests.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.1.jar:/usr/local/Cellar/hadoop/2.6.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b4d876d837b830405ccdb6af94742f99d49f9c04; compiled by 'jenkins' on 2015-09-16T21:07Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2017-09-22 10:44:34,374 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-09-22 10:44:34,377 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-09-22 10:44:34,701 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-09-22 10:44:34,808 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-09-22 10:44:34,809 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-09-22 10:44:34,810 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2017-09-22 10:44:34,811 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2017-09-22 10:44:34,887 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-22 10:44:35,020 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2017-09-22 10:44:35,068 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-09-22 10:44:35,072 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-09-22 10:44:35,084 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-09-22 10:44:35,086 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-09-22 10:44:35,086 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-09-22 10:44:35,086 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-09-22 10:44:35,118 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-09-22 10:44:35,120 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-09-22 10:44:35,145 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-09-22 10:44:35,146 INFO org.mortbay.log: jetty-6.1.26
2017-09-22 10:44:35,361 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2017-09-22 10:44:35,390 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-22 10:44:35,390 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-09-22 10:44:35,422 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2017-09-22 10:44:35,427 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2017-09-22 10:44:35,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-09-22 10:44:35,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-09-22 10:44:35,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-09-22 10:44:35,476 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 sep 22 10:44:35
2017-09-22 10:44:35,478 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-09-22 10:44:35,479 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 10:44:35,481 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2017-09-22 10:44:35,481 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-09-22 10:44:35,490 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-09-22 10:44:35,491 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2017-09-22 10:44:35,491 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-09-22 10:44:35,491 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-09-22 10:44:35,491 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-09-22 10:44:35,491 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2017-09-22 10:44:35,491 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-09-22 10:44:35,491 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-09-22 10:44:35,491 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-09-22 10:44:35,499 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = Jocke (auth:SIMPLE)
2017-09-22 10:44:35,499 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-09-22 10:44:35,499 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-09-22 10:44:35,499 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2017-09-22 10:44:35,502 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-09-22 10:44:35,704 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-09-22 10:44:35,704 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 10:44:35,704 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2017-09-22 10:44:35,704 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-09-22 10:44:35,705 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2017-09-22 10:44:35,711 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-09-22 10:44:35,711 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 10:44:35,711 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2017-09-22 10:44:35,711 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-09-22 10:44:35,713 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-09-22 10:44:35,713 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-09-22 10:44:35,713 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-09-22 10:44:35,713 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-09-22 10:44:35,714 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-09-22 10:44:35,715 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-09-22 10:44:35,715 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-09-22 10:44:35,715 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2017-09-22 10:44:35,715 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-09-22 10:44:35,719 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2017-09-22 10:44:35,719 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2017-09-22 10:44:35,719 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2017-09-22 10:44:35,740 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/Cellar/hadoop/hdfs/tmp2/dfs/name/in_use.lock acquired by nodename 62423@Joakims-MacBook-Pro.local
2017-09-22 10:44:35,809 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /usr/local/Cellar/hadoop/hdfs/tmp2/dfs/name/current
2017-09-22 10:44:35,858 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /usr/local/Cellar/hadoop/hdfs/tmp2/dfs/name/current/edits_inprogress_0000000000000000003 -> /usr/local/Cellar/hadoop/hdfs/tmp2/dfs/name/current/edits_0000000000000000003-0000000000000000003
2017-09-22 10:44:35,896 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2017-09-22 10:44:35,925 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-09-22 10:44:35,925 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 2 from /usr/local/Cellar/hadoop/hdfs/tmp2/dfs/name/current/fsimage_0000000000000000002
2017-09-22 10:44:35,925 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6b7906b3 expecting start txid #3
2017-09-22 10:44:35,926 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /usr/local/Cellar/hadoop/hdfs/tmp2/dfs/name/current/edits_0000000000000000003-0000000000000000003
2017-09-22 10:44:35,929 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/usr/local/Cellar/hadoop/hdfs/tmp2/dfs/name/current/edits_0000000000000000003-0000000000000000003' to transaction ID 3
2017-09-22 10:44:35,933 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /usr/local/Cellar/hadoop/hdfs/tmp2/dfs/name/current/edits_0000000000000000003-0000000000000000003 of size 1048576 edits # 1 loaded in 0 seconds
2017-09-22 10:44:35,935 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-09-22 10:44:35,936 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4
2017-09-22 10:44:36,078 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-09-22 10:44:36,078 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 359 msecs
2017-09-22 10:44:36,291 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2017-09-22 10:44:36,298 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-09-22 10:44:36,309 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2017-09-22 10:44:36,334 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-09-22 10:44:36,347 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-22 10:44:36,347 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2017-09-22 10:44:36,347 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2017-09-22 10:44:36,348 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2017-09-22 10:44:36,348 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2017-09-22 10:44:36,348 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-09-22 10:44:36,361 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2017-09-22 10:44:36,361 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-09-22 10:44:36,361 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2017-09-22 10:44:36,361 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-09-22 10:44:36,361 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2017-09-22 10:44:36,362 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2017-09-22 10:44:36,375 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-09-22 10:44:36,375 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-09-22 10:44:36,377 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2017-09-22 10:44:36,377 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-09-22 10:44:36,381 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-09-22 10:44:36,381 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 291571504 milliseconds
2017-09-22 10:44:36,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-09-22 10:44:40,499 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, datanodeUuid=87b73037-5265-4062-ab2a-5fc99bc12733, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-1a207d0b-a6a6-4025-85b9-f75ccda1fcb0;nsid=1188721184;c=0) storage 87b73037-5265-4062-ab2a-5fc99bc12733
2017-09-22 10:44:40,507 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2017-09-22 10:44:40,508 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2017-09-22 10:44:40,583 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2017-09-22 10:44:40,583 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-71188f24-74f5-441b-ba70-8601b599671b for DN 127.0.0.1:50010
2017-09-22 10:44:40,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-71188f24-74f5-441b-ba70-8601b599671b,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-09-22 10:44:40,623 INFO BlockStateChange: BLOCK* processReport: from storage DS-71188f24-74f5-441b-ba70-8601b599671b node DatanodeRegistration(127.0.0.1, datanodeUuid=87b73037-5265-4062-ab2a-5fc99bc12733, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-1a207d0b-a6a6-4025-85b9-f75ccda1fcb0;nsid=1188721184;c=0), blocks: 0, hasStaleStorages: false, processing time: 1 msecs
2017-09-22 10:45:06,381 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-09-22 10:45:06,382 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:45:36,385 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30004 milliseconds
2017-09-22 10:45:36,385 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:45:45,641 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2017-09-22 10:45:45,642 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-09-22 10:45:45,642 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4
2017-09-22 10:45:45,642 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 4 
2017-09-22 10:45:45,650 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 11 
2017-09-22 10:45:45,653 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /usr/local/Cellar/hadoop/hdfs/tmp2/dfs/name/current/edits_inprogress_0000000000000000004 -> /usr/local/Cellar/hadoop/hdfs/tmp2/dfs/name/current/edits_0000000000000000004-0000000000000000005
2017-09-22 10:45:45,653 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 6
2017-09-22 10:45:46,832 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0,00s at 0,00 KB/s
2017-09-22 10:45:46,832 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000005 size 352 bytes.
2017-09-22 10:45:46,835 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2
2017-09-22 10:45:46,835 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/usr/local/Cellar/hadoop/hdfs/tmp2/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-09-22 10:46:06,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-09-22 10:46:06,394 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 10 millisecond(s).
2017-09-22 10:46:36,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:46:36,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:47:06,389 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-09-22 10:47:06,390 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:47:36,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-09-22 10:47:36,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:48:06,393 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:48:06,393 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:48:36,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:48:36,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:49:06,398 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-09-22 10:49:06,398 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:49:36,402 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:49:36,402 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:50:06,406 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:50:06,413 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 7 millisecond(s).
2017-09-22 10:50:36,409 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30004 milliseconds
2017-09-22 10:50:36,409 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:51:06,410 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-09-22 10:51:06,417 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 7 millisecond(s).
2017-09-22 10:51:36,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:51:36,421 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 7 millisecond(s).
2017-09-22 10:52:06,416 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-09-22 10:52:06,417 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-09-22 10:52:36,418 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-09-22 10:52:36,419 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:53:06,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:53:06,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:53:36,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:53:36,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:54:06,428 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-09-22 10:54:06,428 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:54:36,432 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30004 milliseconds
2017-09-22 10:54:36,432 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:55:06,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:55:06,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:55:36,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30004 milliseconds
2017-09-22 10:55:36,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:56:06,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-09-22 10:56:06,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:56:36,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:56:36,444 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:57:06,447 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:57:06,447 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:57:36,452 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:57:36,452 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:58:06,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:58:06,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:58:36,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:58:36,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 10:59:06,464 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 10:59:06,464 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 10:59:36,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-09-22 10:59:36,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 11:00:06,468 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30004 milliseconds
2017-09-22 11:00:06,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 11:00:36,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 11:00:36,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 11:01:06,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-09-22 11:01:06,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 11:01:36,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-09-22 11:01:36,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 11:01:59,758 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 4 
2017-09-22 11:01:59,879 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part0. BP-397572744-218.38.137.27-1506042209030 blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]}
2017-09-22 11:02:00,198 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073741825_1001{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2017-09-22 11:02:00,208 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741825_1001{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]} size 118
2017-09-22 11:02:00,618 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part0 is closed by DFSClient_NONMAPREDUCE_-519788700_1
2017-09-22 11:02:00,625 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part1. BP-397572744-218.38.137.27-1506042209030 blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]}
2017-09-22 11:02:00,633 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]} size 0
2017-09-22 11:02:00,637 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part1 is closed by DFSClient_NONMAPREDUCE_-519788700_1
2017-09-22 11:02:00,643 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part2. BP-397572744-218.38.137.27-1506042209030 blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]}
2017-09-22 11:02:00,650 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]} size 0
2017-09-22 11:02:00,652 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part2 is closed by DFSClient_NONMAPREDUCE_-519788700_1
2017-09-22 11:02:00,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part3. BP-397572744-218.38.137.27-1506042209030 blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]}
2017-09-22 11:02:00,683 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]} size 0
2017-09-22 11:02:00,686 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part3 is closed by DFSClient_NONMAPREDUCE_-519788700_1
2017-09-22 11:02:00,696 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part4. BP-397572744-218.38.137.27-1506042209030 blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]}
2017-09-22 11:02:00,708 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]} size 0
2017-09-22 11:02:00,709 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part4 is closed by DFSClient_NONMAPREDUCE_-519788700_1
2017-09-22 11:02:00,716 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part5. BP-397572744-218.38.137.27-1506042209030 blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]}
2017-09-22 11:02:00,727 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]} size 0
2017-09-22 11:02:00,729 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part5 is closed by DFSClient_NONMAPREDUCE_-519788700_1
2017-09-22 11:02:00,736 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part6. BP-397572744-218.38.137.27-1506042209030 blk_1073741831_1007{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]}
2017-09-22 11:02:00,749 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741831_1007{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]} size 0
2017-09-22 11:02:00,750 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part6 is closed by DFSClient_NONMAPREDUCE_-519788700_1
2017-09-22 11:02:00,756 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part7. BP-397572744-218.38.137.27-1506042209030 blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]}
2017-09-22 11:02:00,765 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]} size 0
2017-09-22 11:02:00,767 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part7 is closed by DFSClient_NONMAPREDUCE_-519788700_1
2017-09-22 11:02:00,779 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part8. BP-397572744-218.38.137.27-1506042209030 blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]}
2017-09-22 11:02:00,801 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]} size 0
2017-09-22 11:02:00,804 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part8 is closed by DFSClient_NONMAPREDUCE_-519788700_1
2017-09-22 11:02:00,811 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part9. BP-397572744-218.38.137.27-1506042209030 blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]}
2017-09-22 11:02:00,825 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]} size 0
2017-09-22 11:02:00,828 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/in/part9 is closed by DFSClient_NONMAPREDUCE_-519788700_1
2017-09-22 11:02:03,328 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/out/reduce-out. BP-397572744-218.38.137.27-1506042209030 blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]}
2017-09-22 11:02:03,338 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]} size 0
2017-09-22 11:02:03,341 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/out/reduce-out is closed by DFSClient_NONMAPREDUCE_-519788700_1
2017-09-22 11:02:03,344 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/out/_temporary/0/_temporary/attempt_local1028467859_0001_r_000000_0/part-r-00000. BP-397572744-218.38.137.27-1506042209030 blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]}
2017-09-22 11:02:03,358 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]} size 0
2017-09-22 11:02:03,364 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/out/_temporary/0/_temporary/attempt_local1028467859_0001_r_000000_0/part-r-00000 is closed by DFSClient_NONMAPREDUCE_-519788700_1
2017-09-22 11:02:03,469 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/Jocke/QuasiMonteCarlo_1506045718654_1164164680/out/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-519788700_1
2017-09-22 11:02:03,834 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741825_1001 127.0.0.1:50010 
2017-09-22 11:02:03,834 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741826_1002 127.0.0.1:50010 
2017-09-22 11:02:03,834 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741827_1003 127.0.0.1:50010 
2017-09-22 11:02:03,834 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741828_1004 127.0.0.1:50010 
2017-09-22 11:02:03,834 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741829_1005 127.0.0.1:50010 
2017-09-22 11:02:03,834 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741830_1006 127.0.0.1:50010 
2017-09-22 11:02:03,834 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741831_1007 127.0.0.1:50010 
2017-09-22 11:02:03,835 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741832_1008 127.0.0.1:50010 
2017-09-22 11:02:03,835 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741833_1009 127.0.0.1:50010 
2017-09-22 11:02:03,835 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741834_1010 127.0.0.1:50010 
2017-09-22 11:02:03,835 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741836_1012 127.0.0.1:50010 
2017-09-22 11:02:03,835 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741835_1011 127.0.0.1:50010 
2017-09-22 11:02:04,369 INFO BlockStateChange: BLOCK* BlockManager: ask 127.0.0.1:50010 to delete [blk_1073741825_1001, blk_1073741826_1002, blk_1073741827_1003, blk_1073741828_1004, blk_1073741829_1005, blk_1073741830_1006, blk_1073741831_1007, blk_1073741832_1008, blk_1073741833_1009, blk_1073741834_1010, blk_1073741835_1011, blk_1073741836_1012]
2017-09-22 11:02:06,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-09-22 11:02:06,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 11:02:36,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-09-22 11:02:36,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 11:03:06,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-09-22 11:03:06,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 11:03:31,132 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 77 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 1 Number of syncs: 46 SyncTimes(ms): 45 
2017-09-22 11:03:31,162 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/Jocke/inputwc.txt._COPYING_. BP-397572744-218.38.137.27-1506042209030 blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]}
2017-09-22 11:03:31,294 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]} size 0
2017-09-22 11:03:31,302 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/Jocke/inputwc.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-489790534_1
2017-09-22 11:03:36,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-09-22 11:03:36,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 11:04:06,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-09-22 11:04:06,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 11:04:21,640 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/Jocke/outputwc/_temporary/0/_temporary/attempt_local467372790_0001_r_000000_0/part-r-00000. BP-397572744-218.38.137.27-1506042209030 blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]}
2017-09-22 11:04:21,740 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-71188f24-74f5-441b-ba70-8601b599671b:NORMAL:127.0.0.1:50010|RBW]]} size 0
2017-09-22 11:04:21,746 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/Jocke/outputwc/_temporary/0/_temporary/attempt_local467372790_0001_r_000000_0/part-r-00000 is closed by DFSClient_NONMAPREDUCE_1867090564_1
2017-09-22 11:04:21,796 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/Jocke/outputwc/_SUCCESS is closed by DFSClient_NONMAPREDUCE_1867090564_1
2017-09-22 11:04:36,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-09-22 11:04:36,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 11:05:06,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30004 milliseconds
2017-09-22 11:05:06,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 11:05:36,478 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30004 milliseconds
2017-09-22 11:05:36,478 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 11:06:06,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-09-22 11:06:06,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 11:06:36,481 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 11:06:36,481 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 11:07:06,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 11:07:06,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 11:07:36,490 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 11:07:36,490 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 11:08:06,493 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30004 milliseconds
2017-09-22 11:08:06,493 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 11:08:36,493 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-09-22 11:08:36,493 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 11:09:06,492 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-09-22 11:09:06,494 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-09-22 11:09:36,494 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30004 milliseconds
2017-09-22 11:09:36,501 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 7 millisecond(s).
2017-09-22 11:10:06,497 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-09-22 11:10:06,498 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 11:10:36,496 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-09-22 11:10:36,497 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 11:11:06,500 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30004 milliseconds
2017-09-22 11:11:06,501 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 11:11:36,499 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-09-22 11:11:36,500 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 11:12:06,500 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-09-22 11:12:06,500 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 11:12:36,500 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-09-22 11:12:36,500 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 11:13:06,501 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-09-22 11:13:06,502 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 11:13:36,502 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-09-22 11:13:36,503 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 11:14:06,505 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-09-22 11:14:06,505 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 11:14:36,505 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-09-22 11:14:36,505 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 11:15:06,509 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-09-22 11:15:06,509 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 11:15:36,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30006 milliseconds
2017-09-22 11:15:36,514 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-09-22 11:16:06,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-09-22 11:16:06,515 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-09-22 11:16:30,322 INFO BlockStateChange: BLOCK* processReport: from storage DS-71188f24-74f5-441b-ba70-8601b599671b node DatanodeRegistration(127.0.0.1, datanodeUuid=87b73037-5265-4062-ab2a-5fc99bc12733, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-1a207d0b-a6a6-4025-85b9-f75ccda1fcb0;nsid=1188721184;c=0), blocks: 2, hasStaleStorages: false, processing time: 1 msecs
2017-09-22 11:16:36,515 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-09-22 11:16:36,515 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
